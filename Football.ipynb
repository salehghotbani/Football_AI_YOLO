{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707ab6a17b7304f7",
   "metadata": {},
   "source": [
    "[![Python](https://img.shields.io/badge/Python%203.11-red?logo=python&logoColor=fff)](#)\n",
    "[![CUDA](https://img.shields.io/badge/CUDA_Toolkit-12.9-blue)](#)\n",
    "[![cuDNN](https://img.shields.io/badge/cuDNN-9.8.0-blue)](#)\n",
    "[![YOLO](https://img.shields.io/badge/YOLO-green)](#)\n",
    "[![tensorrt](https://img.shields.io/badge/Tensorrt-10.11.0.33-cyan)](#)\n",
    "[![Roboflow](https://img.shields.io/badge/Roboflow-orange)](#)\n",
    "\n",
    "# Detect and track players, ball and referee in football match using `YOLO v11`, `Tensorrt`, `roboflow` and `supervision` packages.\n",
    "\n",
    "> The idea and main code of this project were provided by Roboflow [Link](https://github.com/roboflow/notebooks/blob/main/notebooks/football-ai.ipynb). This project has only made minor modifications to it.\n",
    "\n",
    "- Using `roboflow` to create dataset\n",
    "- Using `YOLO` to train model and detect players and ball\n",
    "- Using `supervision` to visualize boxes around detected objects and set label for them\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8dafa93e1de453",
   "metadata": {},
   "source": [
    "### Install pytorch compatible with `CUDA`\n",
    "#### First of all, download and install `CUDA toolkit` compatible with your Nvidia graphics card from [this link](https://developer.nvidia.com/cuda-downloads)\n",
    "#### Then Install `CUDNN` from [this link](https://developer.nvidia.com/cudnn-downloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad48215e499c4ec",
   "metadata": {},
   "source": [
    "#### Then install `pytorch` from [this guid](https://pytorch.org/get-started/locally/):\n",
    "\n",
    "![installing pytorch compatible to CUDA platform](/docs/images/torch.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e921a9f22f11e3ed",
   "metadata": {},
   "source": "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "99f169debd5715c7",
   "metadata": {},
   "source": [
    "---\n",
    "### Verify Nvidia is accessible\n",
    "the result of this command should be like this:\n",
    "```\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 572.70                 Driver Version: 572.70         CUDA Version: 12.8     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
    "| N/A   42C    P8              1W /   43W |      18MiB /   8188MiB |      0%      Default |\n",
    "|                                         |                        |                  N/A |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c58ca85dbaf77678",
   "metadata": {},
   "source": [
    "-----\n",
    "### install required packages"
   ]
  },
  {
   "cell_type": "code",
   "id": "29a3f77812cae581",
   "metadata": {},
   "source": "!pip install -q ultralytics roboflow supervision opencv-python numpy",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install git+https://github.com/roboflow/sports.git",
   "id": "b180a677df2793c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "441bf0c4756c2cdc",
   "metadata": {},
   "source": [
    "---\n",
    "### Download ball, players and referee detection dataset from [this link](https://universe.roboflow.com/roboflow-jvuqo/football-players-detection-3zvbc)\n",
    "\n",
    "![player_dataset](/docs/images/player_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2df41cc71a900b",
   "metadata": {},
   "source": [
    "---\n",
    "### Download base model of `YOLO` form [this link](https://docs.ultralytics.com/tasks/detect/#models)\n",
    "![models image](/docs/images/yolo.png)\n",
    "#### I used `YOLO11s`\n",
    "> You can skip the YOLO model download section.\n",
    "> When using the model defined in the code, if it has not been downloaded, it will be downloaded automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad310955f09ead2",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "8bb38b7f3cb7bea3",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "from sports.common.team import TeamClassifier\n",
    "import supervision as sv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8dc5e5fbe2263cc",
   "metadata": {},
   "source": [
    "---\n",
    "### Predefined Variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "22b8feb739dbee4b",
   "metadata": {},
   "source": [
    "HOME = os.getcwd()\n",
    "print(torch.cuda.is_available())\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### The result of the print show that the CUDA is accessible or not\n",
    "> if you have installed all necessary apps and packages based on this guid, you have to access the cuda!"
   ],
   "id": "b62872b68e68107c"
  },
  {
   "cell_type": "markdown",
   "id": "6777c2bbdbf5f7ad",
   "metadata": {},
   "source": [
    "---\n",
    "### Train model to detect `players`, `ball` and `referee`"
   ]
  },
  {
   "cell_type": "code",
   "id": "b36a89f7c7805285",
   "metadata": {},
   "source": [
    "base_model = YOLO(f'{HOME}/yolo11s.pt')\n",
    "base_model.train(data=f\"{HOME}/football/data.yaml\", epochs=50, batch=4, imgsz=1280, plots=True, device=DEVICE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trained_model = f\"{HOME}/runs/detect/trainv11s/weights/best.pt\"",
   "id": "e69b80f1f6fe9a99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Define source video path to detect players, referees and ball in it.",
   "id": "bfdd98b38cc88444"
  },
  {
   "cell_type": "code",
   "id": "cd9bd060fc837c75",
   "metadata": {},
   "source": [
    "SOURCE_VIDEO_PATH = f\"{HOME}/clips/download3.mp4\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "408814021308c47d",
   "metadata": {},
   "source": [
    "--------\n",
    "### Validate trained model"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c81b7dfa71bf2c6",
   "metadata": {},
   "source": [
    "model = YOLO(trained_model)\n",
    "model.val(data=f'{HOME}/football/data.yaml', imgsz=1280, device=DEVICE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "--------\n",
    "### Convert the Yolo model to TensorRT"
   ],
   "id": "f90583ef5491fb0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = YOLO(trained_model)\n",
    "model.export(format=\"engine\", imgsz=1280, device=DEVICE, dynamic=True)"
   ],
   "id": "893cd74fdee496f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Our Model Trained Path\n",
    "##### Go to the `/runs/detect/` directory to see the trained model directory.\n",
    "> [!IMPORTANT]\n",
    "> Attention: Every time you train the model, a new directory in `/runs/detect/` will be created, even if you cancel training process! so be careful to define the path of trained model!"
   ],
   "id": "8995431ebe29785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "OUR_MODEL_PATH = f\"{HOME}/runs/detect/trainv11s/weights/best.engine\"",
   "id": "4c5d300c8bb3d7b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7d98c8341ae5b9ae",
   "metadata": {},
   "source": [
    "---\n",
    "### You can download some football match clips form this links\n",
    "\n",
    "- https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\n",
    "- https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\n",
    "- https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\n",
    "- https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\n",
    "- https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047c48a7c0f52cc",
   "metadata": {},
   "source": [
    "---\n",
    "### Object IDs (Class IDs)"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2b13835a0484ce5",
   "metadata": {},
   "source": [
    "BALL_ID = 0\n",
    "GOALKEEPER_ID = 1\n",
    "PLAYER_ID = 2\n",
    "REFEREE_ID = 3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6d26cd543baf01ca",
   "metadata": {},
   "source": [
    "---\n",
    "### Detect `players`, `ball` and `referee` just using `YOLO`"
   ]
  },
  {
   "cell_type": "code",
   "id": "24a95bf9e662eb43",
   "metadata": {},
   "source": [
    "model = YOLO(OUR_MODEL_PATH, task='detect')\n",
    "result = model.predict(source=SOURCE_VIDEO_PATH, show=True, conf=0.4, save=False, device=DEVICE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc1a6c3eefcdac6e",
   "metadata": {},
   "source": [
    "---\n",
    "### Collect Crops Of Players\n",
    "#### To separate the two teams we need to crop the players' pictures."
   ]
  },
  {
   "cell_type": "code",
   "id": "2728aa643942206",
   "metadata": {},
   "source": [
    "STRIDE = 30\n",
    "\n",
    "\n",
    "def extract_crops(source_video_path: str):\n",
    "    frame_generator = sv.get_video_frames_generator(source_video_path, stride=STRIDE)\n",
    "    yolo_model = YOLO(OUR_MODEL_PATH, task='detect')\n",
    "\n",
    "    crops = []\n",
    "    for frame in tqdm(frame_generator, desc=\"Extracting crops...\"):\n",
    "        results = yolo_model(frame, conf=0.3, save=False, device=DEVICE, verbose=False, half=True)\n",
    "        detections = sv.Detections.from_ultralytics(results[0])\n",
    "        detections = detections[detections.class_id == PLAYER_ID]\n",
    "        detections = detections.with_nms(threshold=0.5, class_agnostic=True)\n",
    "        crops += [\n",
    "            sv.crop_image(frame, xyxy)\n",
    "            for xyxy in detections.xyxy\n",
    "        ]\n",
    "    return crops\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ddf90b7614409bd6",
   "metadata": {},
   "source": [
    "crops = extract_crops(SOURCE_VIDEO_PATH)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f73ebf130166b72b",
   "metadata": {},
   "source": [
    "len(crops)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6ffb6ab20c8a6c0",
   "metadata": {},
   "source": [
    "sv.plot_images_grid(crops[:100], grid_size=(10, 10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c790046ec80c195f",
   "metadata": {},
   "source": [
    "---\n",
    "### Team Classification"
   ]
  },
  {
   "cell_type": "code",
   "id": "c3a9e39ed01bb5c0",
   "metadata": {},
   "source": [
    "def resolve_goalkeepers_team_id(players: sv.Detections, goalkeepers: sv.Detections):\n",
    "    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "    team_0_centroid = players_xy[players.class_id == 0].mean(axis=0)\n",
    "    team_1_centroid = players_xy[players.class_id == 1].mean(axis=0)\n",
    "    goalkeepers_team_id = []\n",
    "    for goalkeeper_xy in goalkeepers_xy:\n",
    "        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)\n",
    "        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)\n",
    "        goalkeepers_team_id.append(0 if dist_0 < dist_1 else 1)\n",
    "\n",
    "    return np.array(goalkeepers_team_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8249380c157baf52",
   "metadata": {},
   "source": [
    "### First Frame Result"
   ]
  },
  {
   "cell_type": "code",
   "id": "71a961b9",
   "metadata": {},
   "source": [
    "crops = extract_crops(SOURCE_VIDEO_PATH)\n",
    "team_classifier = TeamClassifier(device=DEVICE)\n",
    "team_classifier.fit(crops)\n",
    "\n",
    "yolo_model = YOLO(OUR_MODEL_PATH, task='detect')\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=20,\n",
    "    height=17,\n",
    ")\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "results = yolo_model(frame, conf=0.4, save=False, device=DEVICE, verbose=False, half=True)[0]\n",
    "\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nmm(threshold=0.5, class_agnostic=True)\n",
    "\n",
    "players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n",
    "referees_detections.class_id -= 1\n",
    "\n",
    "all_detections = sv.Detections.merge([players_detections, goalkeepers_detections, referees_detections])\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_detections)\n",
    "annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)\n",
    "sv.plot_image(annotated_frame)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4874698df30049e",
   "metadata": {},
   "source": [
    "### Clip Result"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce2a18d39dc2609e",
   "metadata": {},
   "source": [
    "crops = extract_crops(SOURCE_VIDEO_PATH)\n",
    "team_classifier = TeamClassifier(device=DEVICE)\n",
    "team_classifier.fit(crops)\n",
    "\n",
    "yolo_model = YOLO(OUR_MODEL_PATH, task='detect')\n",
    "\n",
    "ellipse_annotator = sv.EllipseAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
    "    thickness=2\n",
    ")\n",
    "\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex('#FFD700'),\n",
    "    base=20,\n",
    "    height=17,\n",
    ")\n",
    "\n",
    "TARGET_VIDEO_PATH = f\"{HOME}/result_clips/result_team_classification.mp4\"\n",
    "\n",
    "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "video_sink = sv.VideoSink(TARGET_VIDEO_PATH, video_info=video_info)\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "\n",
    "with video_sink:\n",
    "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
    "        results = yolo_model(frame, conf=0.4, save=False, device=DEVICE, verbose=False, half=True)[0]\n",
    "\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "        ball_detections = detections[detections.class_id == BALL_ID]\n",
    "        ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "        all_detections = detections[detections.class_id != BALL_ID]\n",
    "        all_detections = all_detections.with_nmm(threshold=0.5, class_agnostic=True)\n",
    "\n",
    "        players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "        goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "        referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "        players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "        players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "        goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n",
    "        referees_detections.class_id -= 1\n",
    "\n",
    "        all_detections = sv.Detections.merge([players_detections, goalkeepers_detections, referees_detections])\n",
    "\n",
    "        annotated_frame = frame.copy()\n",
    "        annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_detections)\n",
    "        annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)\n",
    "\n",
    "        video_sink.write_frame(annotated_frame)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![result_team_classification](/docs/clips/result_team_classification.gif)",
   "id": "36e04bd2b528e02d"
  },
  {
   "cell_type": "markdown",
   "id": "4c042f1952e21233",
   "metadata": {},
   "source": [
    "---\n",
    "## Pitch keypoint detector\n",
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "id": "89e8df3f9f813ad2",
   "metadata": {},
   "source": [
    "pose_model = YOLO(f\"{HOME}/yolo11x-pose.pt\")\n",
    "pose_model.train(data=f\"{HOME}/fieldDetection/data.yaml\", task='pose', epochs=12, batch=40, imgsz=640, mosaic=0.0,\n",
    "                 plots=True, device=DEVICE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Attention: Every time you train the model, a new directory in `/runs/pose/` will be created, even if you cancel training process! so be careful to define the path of trained model!",
   "id": "2c9b92bdf7a32938"
  },
  {
   "cell_type": "code",
   "id": "e9123b3768f4838f",
   "metadata": {},
   "source": "trained_pose_estimation_model = f'{HOME}/runs/pose/trainv11x/weights/best.pt'",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "732b0722",
   "metadata": {},
   "source": [
    "### Validate Trained model"
   ]
  },
  {
   "cell_type": "code",
   "id": "bfb79134",
   "metadata": {},
   "source": [
    "model_trained = YOLO(trained_pose_estimation_model)\n",
    "model_trained.val(data=f\"{HOME}/fieldDetection/data.yaml\", task='pose', imgsz=640, device=DEVICE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Convert Yolo pose estimation model to Tensorrt",
   "id": "461fec544ef5e989"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = YOLO(trained_pose_estimation_model)\n",
    "model.export(format=\"engine\", imgsz=640, device=DEVICE, dynamic=True)"
   ],
   "id": "b85d7216389e4625",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "PITCH_KEYPOINTS_MODEL_PATH = f'{HOME}/runs/pose/trainv11x/weights/best.engine'",
   "id": "cf8cbfd40718faba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Pose estimation of football pitch\n",
    "#### First Frame"
   ],
   "id": "b6b912198999761b"
  },
  {
   "cell_type": "code",
   "id": "4669d9db9b3d5ae1",
   "metadata": {},
   "source": [
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8\n",
    ")\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "yolo_pitch_keypoint_model = YOLO(PITCH_KEYPOINTS_MODEL_PATH, task='pose')\n",
    "result = yolo_pitch_keypoint_model(frame, conf=0.3)[0]\n",
    "\n",
    "key_points = sv.KeyPoints.from_ultralytics(result)\n",
    "\n",
    "filter = key_points.confidence[0] > 0.5\n",
    "frame_reference_points = key_points.xy[0][filter]\n",
    "frame_generator_key_points = sv.KeyPoints(xy=frame_reference_points[np.newaxis])\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = vertex_annotator.annotate(annotated_frame, frame_generator_key_points)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8981a1f4273e47e",
   "metadata": {},
   "source": [
    "key_points.confidence[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3a34439eb7dcbc8",
   "metadata": {},
   "source": "### Video Result of pose estimation of football pitch"
  },
  {
   "cell_type": "code",
   "id": "519733c873899506",
   "metadata": {},
   "source": [
    "yolo_pitch_keypoint_model = YOLO(PITCH_KEYPOINTS_MODEL_PATH, task='pose')\n",
    "\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8\n",
    ")\n",
    "\n",
    "TARGET_VIDEO_PATH = f\"{HOME}/result_clips/result_pitch2.mp4\"\n",
    "\n",
    "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "video_sink = sv.VideoSink(TARGET_VIDEO_PATH, video_info=video_info)\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "\n",
    "with video_sink:\n",
    "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
    "        results = yolo_pitch_keypoint_model(frame, conf=0.3, save=False, device=DEVICE)[0]\n",
    "\n",
    "        key_points = sv.KeyPoints.from_ultralytics(results)\n",
    "        if not key_points.confidence is None:\n",
    "            filter = key_points.confidence[0] > 0.5\n",
    "            frame_reference_points = key_points.xy[0][filter]\n",
    "            frame_reference_key_points = sv.KeyPoints(xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "            annotated_frame = frame.copy()\n",
    "            annotated_frame = vertex_annotator.annotate(scene=annotated_frame, key_points=frame_reference_key_points)\n",
    "\n",
    "            video_sink.write_frame(annotated_frame)\n",
    "        else:\n",
    "            video_sink.write_frame(frame)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Football pitch in sports package",
   "id": "6f6dd57452740537"
  },
  {
   "cell_type": "code",
   "id": "6eb642bb",
   "metadata": {},
   "source": [
    "from sports.annotators.soccer import draw_pitch\n",
    "from sports.configs.soccer import SoccerPitchConfiguration\n",
    "\n",
    "CONFIG = SoccerPitchConfiguration()\n",
    "\n",
    "annotated_frame = draw_pitch(CONFIG)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4dafdd09",
   "metadata": {},
   "source": [
    "from sports.common.view import ViewTransformer\n",
    "\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8\n",
    ")\n",
    "edge_annotator = sv.EdgeAnnotator(\n",
    "    color=sv.Color.from_hex('#00BFFF'),\n",
    "    thickness=2,\n",
    "    edges=CONFIG.edges\n",
    ")\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "yolo_pitch_keypoint_model = YOLO(PITCH_KEYPOINTS_MODEL_PATH, task='pose')\n",
    "result = yolo_pitch_keypoint_model(frame, conf=0.4)[0]\n",
    "\n",
    "key_points = sv.KeyPoints.from_ultralytics(result)\n",
    "\n",
    "filter = key_points.confidence[0] > 0.5\n",
    "frame_reference_points = key_points.xy[0][filter]\n",
    "frame_reference_key_points = sv.KeyPoints(xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "pitch_reference_pointsd = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "view_transformer = ViewTransformer(\n",
    "    source=pitch_reference_pointsd,\n",
    "    target=frame_reference_points\n",
    ")\n",
    "\n",
    "pitch_all_points = np.array(CONFIG.vertices)\n",
    "frame_all_points = view_transformer.transform_points(pitch_all_points)\n",
    "frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = edge_annotator.annotate(annotated_frame, frame_all_key_points)\n",
    "annotated_frame = vertex_annotator.annotate(annotated_frame, frame_reference_key_points)\n",
    "\n",
    "sv.plot_image(annotated_frame)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3fd8b3d5d1a90181",
   "metadata": {},
   "source": "### Video Result"
  },
  {
   "cell_type": "code",
   "id": "2738b50013a36fa5",
   "metadata": {},
   "source": [
    "yolo_pitch_keypoint_model = YOLO(PITCH_KEYPOINTS_MODEL_PATH, task='pose')\n",
    "\n",
    "vertex_annotator = sv.VertexAnnotator(\n",
    "    color=sv.Color.from_hex('#FF1493'),\n",
    "    radius=8\n",
    ")\n",
    "edge_annotator = sv.EdgeAnnotator(\n",
    "    color=sv.Color.from_hex('#00BFFF'),\n",
    "    thickness=2,\n",
    "    edges=CONFIG.edges\n",
    ")\n",
    "\n",
    "TARGET_VIDEO_PATH = f\"{HOME}/result_clips/result_pitch3.mp4\"\n",
    "\n",
    "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "video_sink = sv.VideoSink(TARGET_VIDEO_PATH, video_info=video_info)\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "\n",
    "with video_sink:\n",
    "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
    "        result = yolo_pitch_keypoint_model(frame, conf=0.3, save=False, device=DEVICE)[0]\n",
    "\n",
    "        key_points = sv.KeyPoints.from_ultralytics(result)\n",
    "\n",
    "        if not key_points.confidence is None:\n",
    "            filter = key_points.confidence[0] > 0.5\n",
    "            frame_reference_points = key_points.xy[0][filter]\n",
    "            frame_reference_key_points = sv.KeyPoints(xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "            pitch_reference_pointsd = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "            view_transformer = ViewTransformer(\n",
    "                source=pitch_reference_pointsd,\n",
    "                target=frame_reference_points\n",
    "            )\n",
    "\n",
    "            pitch_all_points = np.array(CONFIG.vertices)\n",
    "            frame_all_points = view_transformer.transform_points(pitch_all_points)\n",
    "            frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])\n",
    "\n",
    "            annotated_frame = frame.copy()\n",
    "            annotated_frame = edge_annotator.annotate(annotated_frame, frame_all_key_points)\n",
    "            annotated_frame = vertex_annotator.annotate(annotated_frame, frame_reference_key_points)\n",
    "\n",
    "            video_sink.write_frame(annotated_frame)\n",
    "        else:\n",
    "            video_sink.write_frame(frame)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f20db7fbe4e02432",
   "metadata": {},
   "source": [
    "---\n",
    "## Show Players, ball and referees on the pitch\n",
    "### First Frame"
   ]
  },
  {
   "cell_type": "code",
   "id": "d375ada24496481b",
   "metadata": {},
   "source": [
    "from sports.annotators.soccer import draw_pitch, draw_points_on_pitch\n",
    "\n",
    "crops = extract_crops(SOURCE_VIDEO_PATH)\n",
    "team_classifier = TeamClassifier(device=DEVICE)\n",
    "team_classifier.fit(crops)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "yolo_model = YOLO(OUR_MODEL_PATH)\n",
    "results = yolo_model(frame, conf=0.4, save=False, device=DEVICE)[0]\n",
    "\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "ball_detections = detections[detections.class_id == BALL_ID]\n",
    "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "all_detections = detections[detections.class_id != BALL_ID]\n",
    "all_detections = all_detections.with_nmm(threshold=0.5, class_agnostic=True)\n",
    "\n",
    "players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n",
    "\n",
    "result = yolo_pitch_keypoint_model(frame, conf=0.4)[0]\n",
    "\n",
    "key_points = sv.KeyPoints.from_ultralytics(result)\n",
    "\n",
    "filter = key_points.confidence[0] > 0.5\n",
    "frame_reference_points = key_points.xy[0][filter]\n",
    "frame_reference_key_points = sv.KeyPoints(xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "view_transformer = ViewTransformer(\n",
    "    source=frame_reference_points,\n",
    "    target=pitch_reference_points\n",
    ")\n",
    "\n",
    "frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "pitch_ball_xy = view_transformer.transform_points(frame_ball_xy)\n",
    "\n",
    "frame_players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "pitch_players_xy = view_transformer.transform_points(frame_players_xy)\n",
    "\n",
    "frame_referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "pitch_referees_xy = view_transformer.transform_points(frame_referees_xy)\n",
    "\n",
    "pitch = draw_pitch(config=CONFIG)\n",
    "pitch = draw_points_on_pitch(config=CONFIG,\n",
    "                             xy=pitch_ball_xy,\n",
    "                             face_color=sv.Color.WHITE,\n",
    "                             edge_color=sv.Color.BLACK,\n",
    "                             radius=10,\n",
    "                             pitch=pitch\n",
    "                             )\n",
    "pitch = draw_points_on_pitch(config=CONFIG,\n",
    "                             xy=pitch_players_xy[players_detections.class_id == 0],\n",
    "                             face_color=sv.Color.from_hex('#00BFFF'),\n",
    "                             edge_color=sv.Color.BLACK,\n",
    "                             radius=16,\n",
    "                             pitch=pitch\n",
    "                             )\n",
    "pitch = draw_points_on_pitch(config=CONFIG,\n",
    "                             xy=pitch_players_xy[players_detections.class_id == 1],\n",
    "                             face_color=sv.Color.from_hex('#FF1493'),\n",
    "                             edge_color=sv.Color.BLACK,\n",
    "                             radius=16,\n",
    "                             pitch=pitch\n",
    "                             )\n",
    "pitch = draw_points_on_pitch(config=CONFIG,\n",
    "                             xy=pitch_referees_xy,\n",
    "                             face_color=sv.Color.from_hex('#FFD700'),\n",
    "                             edge_color=sv.Color.BLACK,\n",
    "                             radius=10,\n",
    "                             pitch=pitch\n",
    "                             )\n",
    "\n",
    "sv.plot_image(pitch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "db89a884ff629fa5",
   "metadata": {},
   "source": "### Video Result"
  },
  {
   "cell_type": "code",
   "id": "ee06ae778c553310",
   "metadata": {},
   "source": [
    "crops = extract_crops(SOURCE_VIDEO_PATH)\n",
    "team_classifier = TeamClassifier(device=DEVICE)\n",
    "team_classifier.fit(crops)\n",
    "\n",
    "yolo_model = YOLO(OUR_MODEL_PATH, task='pose')\n",
    "\n",
    "TARGET_VIDEO_PATH = f\"{HOME}/result_clips/result_pitch.mp4\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "fps = video_info.fps\n",
    "out = cv2.VideoWriter(TARGET_VIDEO_PATH, fourcc, fps, (1280, 720))\n",
    "\n",
    "with sv.VideoSink(target_path=TARGET_VIDEO_PATH, video_info=video_info, codec='MJPEG'):\n",
    "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
    "        results = yolo_model(frame, conf=0.4, save=False, device=DEVICE, verbose=False, half=True)[0]\n",
    "\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "        ball_detections = detections[detections.class_id == BALL_ID]\n",
    "        ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
    "\n",
    "        all_detections = detections[detections.class_id != BALL_ID]\n",
    "        all_detections = all_detections.with_nmm(threshold=0.5, class_agnostic=True)\n",
    "\n",
    "        players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
    "        goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
    "        referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
    "\n",
    "        players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
    "        players_detections.class_id = team_classifier.predict(players_crops)\n",
    "\n",
    "        goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n",
    "\n",
    "        result = yolo_pitch_keypoint_model(frame, conf=0.4, save=False, device=DEVICE, verbose=False, half=True)[0]\n",
    "\n",
    "        key_points = sv.KeyPoints.from_ultralytics(result)\n",
    "\n",
    "        filter = key_points.confidence[0] > 0.5\n",
    "        frame_reference_points = key_points.xy[0][filter]\n",
    "        frame_reference_key_points = sv.KeyPoints(xy=frame_reference_points[np.newaxis, ...])\n",
    "\n",
    "        pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
    "\n",
    "        view_transformer = ViewTransformer(source=frame_reference_points, target=pitch_reference_points)\n",
    "\n",
    "        frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "        pitch_ball_xy = view_transformer.transform_points(frame_ball_xy)\n",
    "\n",
    "        frame_players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "        pitch_players_xy = view_transformer.transform_points(frame_players_xy)\n",
    "\n",
    "        frame_referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
    "        pitch_referees_xy = view_transformer.transform_points(frame_referees_xy)\n",
    "\n",
    "        pitch = draw_pitch(config=CONFIG)\n",
    "        pitch = draw_points_on_pitch(config=CONFIG,\n",
    "                                     xy=pitch_ball_xy,\n",
    "                                     face_color=sv.Color.WHITE,\n",
    "                                     edge_color=sv.Color.BLACK,\n",
    "                                     radius=10,\n",
    "                                     pitch=pitch\n",
    "                                     )\n",
    "        pitch = draw_points_on_pitch(config=CONFIG,\n",
    "                                     xy=pitch_players_xy[players_detections.class_id == 0],\n",
    "                                     face_color=sv.Color.from_hex('#00BFFF'),\n",
    "                                     edge_color=sv.Color.BLACK,\n",
    "                                     radius=16,\n",
    "                                     pitch=pitch\n",
    "                                     )\n",
    "        pitch = draw_points_on_pitch(config=CONFIG,\n",
    "                                     xy=pitch_players_xy[players_detections.class_id == 1],\n",
    "                                     face_color=sv.Color.from_hex('#FF1493'),\n",
    "                                     edge_color=sv.Color.BLACK,\n",
    "                                     radius=16,\n",
    "                                     pitch=pitch\n",
    "                                     )\n",
    "        pitch = draw_points_on_pitch(config=CONFIG,\n",
    "                                     xy=pitch_referees_xy,\n",
    "                                     face_color=sv.Color.from_hex('#FFD700'),\n",
    "                                     edge_color=sv.Color.BLACK,\n",
    "                                     radius=16,\n",
    "                                     pitch=pitch\n",
    "                                     )\n",
    "\n",
    "        resized_frame = cv2.resize(pitch, (1280, 720))\n",
    "\n",
    "        out.write(resized_frame)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![result pitch](/docs/clips/result_pitch.gif)",
   "id": "42c274908cb56aa5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
